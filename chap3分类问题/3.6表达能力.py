# 当前版本 ： python3.7.11
# 开发时间 ： 2021/9/13 19:58
"""
针对于模型的表达能力偏弱的问题，可以通过重复堆叠多次变换来增加其表达能力：
                              𝒉1 = ReLU(𝑾1𝒙 + 𝒃1)
                              𝒉2 = ReLU(𝑾2𝒉1 + 𝒃2)
                              o = 𝑾3𝒉2 + 𝒃3
把第一层神经元的输出值𝒉1作为第二层神经元模型的输入，把第二层神经元的输出𝒉2作为第三层神经元的输入，
最后一层神经元的输出作为模型的输出。 从网络结构上看，如图 3.9 所示，函数的嵌套表现为网络层的前后相连，每堆叠一个(非)线性环节，
网络层数增加一层。我们把输入节点𝒙所在的层叫作输入层，每一个非线性模块的输出𝒉𝑖连同它的网络层参数𝑾𝑖和𝒃𝑖称为一层网络层，
特别地，对于网络中间的层，叫作隐藏层，最后一层叫作输出层。
这种由大量神经元模型连接形成的网络结构称为神经网络(Neural Network)。
我们可以看到，神经网络并不难理解，神经网络的每层的节点数和神经网络的层数决定了神经网络的复杂度。
现在我们的网络模型已经升级为 3 层的神经网络，具有较好的非线性表达能力，接下来讨论如何优化网络参数。
"""