# 当前版本 ： python3.7.11
# 开发时间 ： 2021/9/22 10:55
"""
前面我们介绍了数据集需要划分为训练集(Train set)和测试集(Test set)，但是为了挑选模型超参数和检测过拟合现象，
一般需要将原来的训练集再次切分为新的训练集和验证集(Validation set)，即数据集需要切分为训练集、验证集和测试集 3 个子集。

9.3.1验证集与超参数
前面已经介绍了训练集和测试集的区别，训练集𝔻train用于训练模型参数，测试集𝔻test用于测试模型的泛化能力，测试集中的样本不能参与模型的训练，
防止模型“记忆”住数据的特征，损害模型的泛化能力。训练集和测试集都是采样自相同的数据分布，比如MNIST 手写数字图片集共有 7 万张样本图片，
其中 6 万张图片用做训练集，余下的 1 万张图片用于测试集。训练集与测试集的分配比例可以由用户自行定义，比如 80%的数据用于训练，剩下的 20%用于测试。当
数据集规模偏小时，为了测试集能够比较准确地测试出模型的泛化能力，可以适当增加测试集的比例。
下图 9.8 演示了 MNIST 手写数字图片集的划分：80%用于训练，剩下的 20%用于测试。

但是将数据集仅划分为训练集与测试集是不够的，由于测试集的性能不能作为模型训练的反馈，而我们需要在模型训练时能够挑选出较合适的模型超参数，
判断模型是否过拟合等，因此需要将训练集再次切分为训练集𝔻train和验证集𝔻val，如图 9.9 所示。划分过的训练集与原来的训练集的功能一致，
用于训练模型的参数，而验证集则用于选择模型的超参数(模型选择，Model selection)，它的功能包括：
❑ 根据验证集的性能表现来调整学习率、权值衰减系数、训练次数等。
❑ 根据验证集的性能表现来重新调整网络拓扑结构。
❑ 根据验证集的性能表现判断是否过拟合和欠拟合。
和训练集-测试集的划分类似，训练集、验证集和测试集可以按着自定义的比例来划分，比如常见的 60%-20%-20%的划分，图 9.9 演示了 MNIST 手写数据集的划分示意图。

验证集与测试集的区别在于，算法设计人员可以根据验证集的表现来调整模型的各种超参数的设置，提升模型的泛化能力，
但是测试集的表现却不能用来反馈模型的调整，否则测试集将和验证集的功能重合，因此在测试集上的性能表现将无法代表模型的泛化能力。

实际上，部分开发人员会错误地使用测试集来挑选最好的模型，然后将其作为模型泛化性能汇报(甚至部分论文也会出现这种做法)，
此时的测试集其实是验证集的功能，因此汇报的“泛化性能”本质上是验证集上的性能，而不是真正的泛化性能。为了防止出现这种作弊行为，
可以选择生成多个测试集，这样即使开发人员使用了其中一个测试集来挑选模型，我们还可以使用其它测试集来评价模型，这也是 Kaggle 竞赛常用的做法。


9.3.2提前停止
一般把对训练集中的一个 Batch 运算更新一次叫做一个 Step，对训练集的所有样本循环迭代一次叫做一个 Epoch。
验证集可以在数次 Step 或数次 Epoch 后使用，计算模型的验证性能。验证的步骤过于频繁，能够精准地观测模型的训练状况，
但是也会引入额外的计算代价，一般建议几个 Epoch 后进行一次验证运算。

以分类任务为例，在训练时，一般关注的指标有训练误差、训练准确率等，相应地，验证时也有验证误差和验证准确率等，
测试时也有测试误差和测试准确率等。通过观测训练准确率和验证准确率可以大致推断模型是否出现过拟合和欠拟合。
如果模型的训练误差较低，训练准确率较高，但是验证误差较高，验证准确率较低，那么可能出现了过拟合现象。
如果训练集和验证集上面的误差都较高，准确率较低，那么可能出现了欠拟合现象。

当观测到过拟合现象时，可以从新设计网络模型的容量，如降低网络的层数、降低网络的参数量、添加正则化手段、添加假设空间的约束等，
使得模型的实际容量降低，从而减轻或解决过拟合现象；当观测到欠拟合现象时，可以尝试增大网络的容量，如加深网络的层数、增加网络的参数量，尝试更复杂的网络结构。

实际上，由于网络的实际容量可以随着训练的进行发生改变，因此在相同的网络设定下，随着训练的进行，可能观测到不同的过拟合、欠拟合状况。
如图 9.10 所示为分类问题的典型训练曲线，红色曲线为训练准确率，蓝色曲线为测试准确率。从图中可以看到，在训练的前期，随着训练的进行，
模型的训练准确率和测试准确率都呈现增大的趋势，此时并没有出现过拟合现象；在训练后期，即使是相同网络结构下，由于模型的实际容量发生改变，
我们观察到了过拟合的现象，具体表现为训练准确度继续改善，但是泛化能力变弱(测试准确率减低)。

这意味着，对于神经网络，即使网络结构超参数保持不变(即网络最大容量固定)，模型依然可能会出现过拟合的现象，
这是因为神经网络的有效容量和网络参数的状态息息相关，神经网络的有效容量可以很大，也可以通过稀疏化参数、添加正则化等手段降低有效容量。
在训练的前中期，神经网络的过拟合现象没有出现，当随着训练 Epoch 数的增加，过拟合程度越来越严重。图 9.10 中竖直虚线所处的网络状态最佳，
没有出现明显的过拟合现象，网络的泛化能力最佳

那么如何选择合适的 Epoch 就提前停止训练(Early Stopping)，避免出现过拟合现象呢？
我们可以通过观察验证指标的变化，来预测最适合的 Epoch 可能的位置。具体地，对于分类问题，我们可以记录模型的验证准确率，
并监控验证准确率的变化，当发现验证准确率连续𝑛个 Epoch 没有下降时，可以预测可能已经达到了最适合的 Epoch 附近，从而提前终止训练。

图 9.11 中绘制了某次具体的训练过程中，训练和验证准确率随训练 Epoch 的变化曲线，可以观察到，在 Epoch 为 30 左右时，模型达到最佳状态，提前终止训练。

算法 1 是采用提前停止的模型训练算法伪代码。
算法 1：带 Early stopping 功能的网络训练算法
随机初始化参数𝜃
repeat
for 𝑠𝑡𝑒𝑝 = 1, . . . , 𝑁 do
随机采样 Batch {( , 𝑦)}~𝔻train
𝜃 ← 𝜃 − 𝜂∇𝜃ℒ(𝑓( ),𝑦)
end
if 每第𝑛个 Epoch do
测试所有{( , 𝑦)}~𝔻val上的验证性能
 if 验证性能连续数次不提升 do
保存网络状态，提前停止训练
end
do
until 训练达到最大回合数 Epoch
利用保存的网络测试{( ,𝑦)}~𝔻test性能
输出：网络参数𝜃与测试性能
"""