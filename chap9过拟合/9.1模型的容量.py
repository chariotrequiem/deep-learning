# 当前版本 ： python3.7.11
# 开发时间 ： 2021/9/22 10:44
"""
通俗地讲，模型的容量或表达能力，是指模型拟合复杂函数的能力。一种体现模型容量的指标为模型的假设空间(Hypothesis Space)大小，
即模型可以表示的函数集的大小。假设空间越大越完备，从假设空间中搜索出逼近真实模型的函数也就越有可能；
反之，如果假设空间非常受限，就很难从中找到逼近真实模型的函数。
考虑采样自真实分布
𝑝data = {(𝑥, 𝑦)|𝑦 = sin(𝑥), 𝑥 ∈ [−5,5]}
的数据集，从真实分布中采样少量样本点构成训练集，其中包含了观测误差ϵ，如图 9.1 中的小圆点。如果只搜索所有 1 次多项式的模型空间，
令偏置为 0，即𝑦 = 𝑎𝑥，如图 9.1 中 1次多项式的直线所示，则很难找到一条直线较好地逼近真实数据的分布。稍微增大假设空间，
令假设空间为所有的 3 次多项式函数，即𝑦 = 𝑎𝑥3 + 𝑏𝑥2 + 𝑐𝑥，很明显此假设空间明显大于 1 次多项式的假设空间，我们可以找到一条曲线，
如图 9.1 3 次多项式曲线所示，它 比 1 次多项式模型更好地反映了数据的关系，但是仍然不够好。再次增大假设空间，使得可以搜索的函数为 5 次多项式，
即𝑦 = 𝑎𝑥5 + 𝑏𝑥4 + 𝑐𝑥3 + 𝑑𝑥2 + 𝑒𝑥，在此假设空间中，可 以搜索到一个较好的函数，如图 9.1 中 5 次多项式所示。再次增加假设空间后，
如图 9.1 中 7、9、11、13、15、17 次多项式曲线所示，函数的假设空间越大，就越有可能找到一个函数更好地逼近真实分布的函数模型。

但是过大的假设空间无疑会增加搜索难度和计算代价。实际上，在有限的计算资源的约束下，较大的假设空间并不一定能搜索出更好的函数模型。
同时由于观测误差的存在，较大的假设空间中可能包含了大量表达能力过强的函数，能够将训练样本的观测误差也学习进来，从而伤害了模型的泛化能力。
挑选合适容量的学习模型是一个很大的难题。

"""