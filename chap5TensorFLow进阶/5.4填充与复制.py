# 当前版本 ： python3.7.11
# 开发时间 ： 2021/9/15 15:37
"""
5.4.1填充
对于图片数据的高和宽、序列信号的长度，维度长度可能各不相同。为了方便网络的并行计算，需要将不同长度的数据扩张为相同长度，
之前我们介绍了通过复制的方式可以增加数据的长度，但是重复复制数据会破坏原有的数据结构，并不适合于此处。通常的做法是，
在需要补充长度的数据开始或结束处填充足够数量的特定数值，这些特定数值一般代表了无效意义，例如 0，
使得填充后的长度满足系统要求。那么这种操作就叫作填充(Padding)。

考虑 2 个句子张量，每个单词使用数字编码方式表示，如 1 代表 I，2 代表 like 等。第一个句子为：
“I like the weather today.”
我们假设句子数字编码为：[1,2,3,4,5,6]，第二个句子为:
“So do I.”
它的编码为：[7,8,1,6]。
为了能够保存在同一个张量中，我们需要将这两个句子的长度保持一致，也就是说，需要将第二个句子的长度扩充为 6。
常见的填充方案是在句子末尾填充若干数量的 0，变成：
[7,8,1,6,0,0]
此时这两个句子可堆叠合并 shape 为[2,6]的张量。填充操作可以通过 tf.pad(x, paddings)函数实现，
参数 paddings 是包含了多个[Left Padding,Right Padding]的嵌套方案 List，如[[0,0],[2,1],[1,2]]表示第一个维度不填充，
第二个维度左边(起始处)填充两个单元，右边(结束处)填充一个单元，第三个维度左边填充一个单元，右边填充两个单元。
考虑上述 2 个句子的例子，需要在第二个句子的第一个维度的右边填充 2 个单元，则 paddings 方案为[[0,2]]：
In [28]:a = tf.constant([1,2,3,4,5,6]) # 第一个句子
b = tf.constant([7,8,1,6]) # 第二个句子
b = tf.pad(b, [[0,2]]) # 句子末尾填充 2 个 0 b # 填充后的结果
Out[28]:<tf.Tensor: id=3, shape=(6,), dtype=int32, numpy=array([7, 8, 1, 6, 0, 0])>
填充后句子张量形状一致，再将这 2 句子 Stack 在一起，代码如下：
In [29]:tf.stack([a,b],axis=0) # 堆叠合并，创建句子数维度
Out[29]:<tf.Tensor: id=5, shape=(2, 6), dtype=int32, numpy=array([[1, 2, 3, 4, 5, 6],
                                                                  [7, 8, 1, 6, 0, 0]])>

在自然语言处理中，需要加载不同句子长度的数据集，有些句子长度较小，如仅 10 个单词，部份句子长度较长，如超过 100 个单词。
为了能够保存在同一张量中，一般会选取能够覆盖大部分句子长度的阈值，如 80 个单词。对于小于 80 个单词的句子，
在末尾填充相应数量的 0；对大于 80 个单词的句子，截断超过规定长度的部分单词。以 IMDB 数据集的加载为例，
我们来演示如何将不等长的句子变换为等长结构，代码如下：
In [30]:total_words = 10000 # 设定词汇量大小
max_review_len = 80 # 最大句子长度
embedding_len = 100 # 词向量长度
# 加载 IMDB 数据集
(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=total_words)
# 将句子填充或截断到相同长度，设置为末尾填充和末尾截断方式
x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len,truncating='post',padding='post')
x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len,truncating='post',padding='post')
print(x_train.shape, x_test.shape) # 打印等长的句子张量形状
Out[30]: (25000, 80) (25000, 80)

上述代码中，我们将句子的最大长度 max_review_len 设置为 80 个单词，通过keras.preprocessing.sequence.pad_sequences
函数可以快速完成句子的填充和截断工作，以其中某个句子为例，观察其变换后的向量内容：
[ 1 778 128 74 12 630 163 15 4 1766 7982 1051 2 32
 85 156 45 40 148 139 121 664 665 10 10 1361 173 4
 749 2 16 3804 8 4 226 65 12 43 127 24 2 10
 10 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0]
可以看到在句子末尾填充了若干数量的 0，使得句子的长度刚好 80。实际上，也可以选择当句子长度不够时，
在句子前面填充 0；句子长度过长时，截断句首的单词。经过处理后，所有的句子长度都变为 80，
从而训练集可以统一保存在 shape 为[25000,80]的张量中，测试集可以保存 shape 为[25000,80]的张量。


我们来介绍同时在多个维度进行填充的例子。考虑对图片的高宽维度进行填充。以28 × 28大小的图片数据为例，
如果网络层所接受的数据高宽为32 × 32，则必须将28 × 28大小填充到32 × 32，
可以选择在图片矩阵的上、下、左、右方向各填充 2 个单元，如下图 5.2 所示。
上述填充方案可以表达为[[0,0],[2,2],[2,2],[0,0]]，实现如下：
In [31]:
x = tf.random.normal([4,28,28,1])
# 图片上下、左右各填充 2 个单元
tf.pad(x,[[0,0],[2,2],[2,2],[0,0]])
Out[31]:
<tf.Tensor: id=16, shape=(4, 32, 32, 1), dtype=float32, numpy=array([[[[ 0. ],
                                                                       [ 0. ],
                                                                       [ 0. ],…
通过填充操作后，图片的大小变为32 × 32，满足神经网络的输入要求。




5.4.2复制
在维度变换一节，我们就介绍了通过 tf.tile()函数实现长度为 1 的维度复制的功能。tf.tile 函数除了可以对长度为 1 的维度进行复制若干份，
还可以对任意长度的维度进行复制若干份，进行复制时会根据原来的数据次序重复复制。由于前面已经介绍过，此处仅作简单回顾。

通过 tf.tile 函数可以在任意维度将数据重复复制多份，如 shape 为[4,32,32,3]的数据，复制方案为 multiples=[2,3,3,1]，
即通道数据不复制，高和宽方向分别复制 2 份，图片数再复制 1 份，实现如下:
In [32]:x = tf.random.normal([4,32,32,3])
tf.tile(x,[2,3,3,1]) # 数据复制
Out[32]:<tf.Tensor: id=25, shape=(8, 96, 96, 3), dtype=float32, numpy=
array([[[[ 1.20957184e+00, 2.82766962e+00, 1.65782201e+00],
 [ 3.85402292e-01, 2.00732923e+00, -2.79068202e-01],
 [-2.52583921e-01, 7.82584965e-01, 7.56870627e-01],...
"""