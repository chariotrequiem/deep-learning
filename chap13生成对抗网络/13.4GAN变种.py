# 当前版本 ： python3.7.11
# 开发时间 ： 2021/9/26 15:09
"""
在原始的 GAN 论文中，Ian Goodfellow 从理论层面分析了 GAN 网络的收敛性，并且在多个经典图片数据集上测试了图片生成的效果，如图 13.9 所示，
其中图 13.9 (a)为 MNIST 数据，图 13.9 (b)为 Toronto Face 数据集，图 13.9 (c)、图 13.9 (d)为 CIFAR10 数据集。

可以看到，原始 GAN 模型在图片生成效果上并不突出，和 VAE 差别不明显，此时并没有展现出它强大的分布逼近能力。
但是由于 GAN 在理论方面较新颖，实现方面也有很多可以改进的地方，大大地激发了学术界的研究兴趣。在接下来的数年里，
GAN 的研究如火如荼的进行，并且也取得了实质性的进展。接下来我们将介绍几个意义比较重大的 GAN变种。

13.4.1DCGAN
最初始的 GAN 网络主要基于全连接层实现生成器 G 和判别器 D 网络，由于图片的维 度较高，网络参数量巨大，训练的效果并不优秀。
DCGAN [2]提出了使用转置卷积层实现的生成网络，普通卷积层来实现的判别网络，大大地降低了网络参数量，同时图片的生成效果也大幅提升，
展现了 GAN 模型在图片生成效果上超越 VAE 模型的潜质。此外，DCGAN 作者还提出了一系列经验性的 GAN 网络训练技巧，
这些技巧在 WGAN 提出之前被证实有益于网络的稳定训练。前面我们已经使用 DCGAN 模型完成了二次元动漫头像的图片生成实战。

13.4.2InfoGAN
InfoGAN [3]尝试使用无监督的方式去学习输入𝒙的可解释隐向量𝒛的表示方法(Interpretable Representation)，即希望隐向量𝒛能够对应到数据的语义特征。
比如对于MNIST 手写数字图片，我们可以认为数字的类别、字体大小和书写风格等是图片的隐藏变量，希望模型能够学习到这些分离的(Disentangled)可解释特征表示方法，
从而可以通过人 为控制隐变量来生成指定内容的样本。对于 CelebA 名人照片数据集，希望模型可以把发型、眼镜佩戴情况、面部表情等特征分隔开，从而生成指定形态的人脸图片。

分离的可解释特征有什么好处呢？它可以让神经网络的可解释性更强，比如𝒛包含了一些分离的可解释特征，
那么我们可以通过仅仅改变这一个位置上面的特征来获得不同语义的生成数据，如图 13.10 所示，通过将“戴眼镜男士”与“不戴眼镜男士”的隐向量相减，
并与“不戴眼镜女士”的隐向量相加，可以生成“戴眼镜女士”的生成图片。

13.4.3CycleGAN
CycleGAN [4]是华人朱俊彦提出的无监督方式进行图片风格相互转换的算法，由于算法清晰简单，实验效果完成的较好，这项工作受到了很多的赞誉。
CycleGAN 基本的假设是，如果由图片 A 转换到图片 B，再从图片 B 转换到A′，那么A′应该和 A 是同一张图片。因此除了设立标准的 GAN 损失项外，
CycleGAN 还增设了循环一致性损失(Cycle Consistency Loss)，来保证A′尽可能与 A 逼近。CycleGAN 图片的转换效果如图 13.11 所示。

13.4.4WGAN
GAN 的训练问题一直被诟病，很容易出现训练不收敛和模式崩塌的现象。WGAN [5]从理论层面分析了原始的 GAN 使用 JS 散度存在的缺陷，
并提出了可以使用 Wasserstein 距 离来解决这个问题。在 WGAN-GP [6]中，作者提出了通过添加梯度惩罚项，从工程层面很好的实现了 WGAN 算法，
并且实验性证实了 WGAN 训练稳定的优点。

13.4.5Equal GAN
从 GAN 的诞生至 2017 年底，GAN Zoo 已经收集超过了 214 种 GAN 网络变种③。这 些 GAN 的变种或多或少地提出了一些创新，
然而 Google Brain 的几位研究员在 [7]论文中提供了另一个观点：没有证据表明我们测试的 GAN 变种算法一直持续地比最初始的 GAN要好。
论文中对这些 GAN 变种进行了相对公平、全面的比较，在有足够计算资源的情况下，发现几乎所有的 GAN 变种都能达到相似的性能(FID 分数)。
这项工作提醒业界是否这些 GAN 变种具有本质上的创新。

13.4.6  Self-Attention GAN
Attention 机制在自然语言处理(NLP)中间已经用得非常广泛了，Self-Attention GAN(SAGAN) [8]借鉴了 Attention 机制，提出了基于自注意力机制的 GAN 变种。
SAGAN 把图片的逼真度指标：Inception score，从最好的 36.8 提升到 52.52，Frechet Inception distance， 从 27.62 降到 18.65。
从图片生成效果上来看，SAGAN 取得的突破是十分显著的，同时也启发业界对自注意力机制的关注。

13.4.7 Big GAN
在 SAGAN 的基础上，BigGAN [9]尝试将 GAN 的训练扩展到大规模上去，利用正交正则化等技巧保证训练过程的稳定性。
BigGAN 的意义在于启发人们，GAN 网络的训练同样可以从大数据、大算力等方面受益。BigGAN 图片生成效果达到了前所未有的高度：
Inception score 记录提升到 166.5(提高了 52.52)；Frechet Inception Distance 下降到 7.4，降低了 18.65，如图 13.13 所示，
图片的分辨率可达512 × 512，图片细节极其逼真。


"""