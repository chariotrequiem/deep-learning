# å½“å‰ç‰ˆæœ¬ ï¼š python3.7.11
# å¼€å‘æ—¶é—´ ï¼š 2021/9/26 16:39
"""
åœ¨ä»‹ç»å®Œè‡ªå®šä¹‰æ•°æ®é›†çš„åŠ è½½æµç¨‹åï¼Œæˆ‘ä»¬æ¥å®æˆ˜å®å¯æ¢¦æ•°æ®é›†çš„åŠ è½½ä»¥åŠè®­ç»ƒã€‚

15.3.1åˆ›å»ºDatasetå¯¹è±¡
é¦–å…ˆé€šè¿‡ load_pokemon å‡½æ•°è¿”å› imagesã€labels å’Œç¼–ç è¡¨ä¿¡æ¯ï¼Œä»£ç å¦‚ä¸‹ï¼š
# åŠ è½½ pokemon æ•°æ®é›†ï¼ŒæŒ‡å®šåŠ è½½è®­ç»ƒé›†
# è¿”å›è®­ç»ƒé›†çš„æ ·æœ¬è·¯å¾„åˆ—è¡¨ï¼Œæ ‡ç­¾æ•°å­—åˆ—è¡¨å’Œç¼–ç è¡¨å­—å…¸
images, labels, table = load_pokemon('pokemon', 'train')
print('images:', len(images), images)
print('labels:', len(labels), labels)
print('table:', table)
æ„å»º Dataset å¯¹è±¡ï¼Œå¹¶å®Œæˆæ•°æ®é›†çš„éšæœºæ‰“æ•£ã€é¢„å¤„ç†å’Œæ‰¹é‡åŒ–æ“ä½œï¼Œä»£ç å¦‚ä¸‹ï¼š
# images: string path
# labels: number
db = tf.data.Dataset.from_tensor_slices((images, labels))
db = db.shuffle(1000).map(preprocess).batch(32)
æˆ‘ä»¬åœ¨ä½¿ç”¨ tf.data.Dataset.from_tensor_slices æ„å»ºæ•°æ®é›†æ—¶ä¼ å…¥çš„å‚æ•°æ˜¯ images å’Œ labels ç»„æˆçš„ tupleï¼Œå› æ­¤åœ¨å¯¹ db å¯¹è±¡è¿­ä»£æ—¶ï¼Œ
è¿”å›çš„æ˜¯(ğ‘¿ğ‘–, ğ’€ğ‘–)çš„ tuple å¯¹è±¡ï¼Œå…¶ä¸­ğ‘¿ğ‘–æ˜¯ç¬¬ğ‘– ä¸ª Batch çš„å›¾ç‰‡å¼ é‡æ•°æ®ï¼Œğ’€ğ‘–æ˜¯ç¬¬ğ‘–ä¸ª Batch çš„å›¾ç‰‡æ ‡ç­¾æ•°æ®ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ TensorBoard
å¯è§†åŒ–æ¥æŸ¥çœ‹æ¯æ¬¡éå†çš„å›¾ç‰‡æ ·æœ¬ï¼Œä»£ç å¦‚ä¸‹ï¼š
# åˆ›å»º TensorBoard summary å¯¹è±¡
writter = tf.summary.create_file_writer('logs')
for step, (x,y) in enumerate(db):
    # x: [32, 224, 224, 3]
    # y: [32]
    with writter.as_default():
        x = denormalize(x) # åå‘ normalizeï¼Œæ–¹ä¾¿å¯è§†åŒ–
        # å†™å…¥å›¾ç‰‡æ•°æ®
        tf.summary.image('img',x,step=step,max_outputs=9)
        time.sleep(5) # å»¶è¿Ÿ 5sï¼Œå†æ­¤å¾ªç¯

15.3.2æ•°æ®é¢„å¤„ç†
ä¸Šé¢æˆ‘ä»¬åœ¨æ„å»ºæ•°æ®é›†æ—¶é€šè¿‡è°ƒç”¨.map(preprocess)å‡½æ•°æ¥å®Œæˆæ•°æ®çš„é¢„å¤„ç†å·¥ä½œã€‚ç”±äºç›®å‰æˆ‘ä»¬çš„ images åˆ—è¡¨åªæ˜¯ä¿å­˜äº†æ‰€æœ‰å›¾ç‰‡çš„è·¯å¾„ä¿¡æ¯ï¼Œ
è€Œä¸æ˜¯å›¾ç‰‡çš„å†…å®¹å¼ é‡ï¼Œå› æ­¤éœ€è¦åœ¨é¢„å¤„ç†å‡½æ•°ä¸­å®Œæˆå›¾ç‰‡çš„è¯»å–ä»¥åŠå¼ é‡è½¬æ¢ç­‰å·¥ä½œã€‚

å¯¹äºé¢„å¤„ç†å‡½æ•°(x,y) = preprocess(x,y)ï¼Œå®ƒçš„ä¼ å…¥å‚æ•°éœ€è¦å’Œåˆ›å»º Dataset æ—¶ç»™çš„å‚æ•°çš„æ ¼å¼ä¿å­˜ä¸€è‡´ï¼Œè¿”å›å‚æ•°ä¹Ÿéœ€è¦å’Œä¼ å…¥å‚æ•°çš„æ ¼å¼ä¿å­˜ä¸€è‡´ã€‚
ç‰¹åˆ«åœ°ï¼Œæˆ‘ä»¬åœ¨æ„å»ºæ•°æ®é›†æ—¶ä¼ å…¥(ğ’™, ğ’š)çš„ tuple å¯¹è±¡ï¼Œå…¶ä¸­ğ’™ä¸ºæ‰€æœ‰å›¾ç‰‡çš„è·¯å¾„åˆ—è¡¨ï¼Œğ’šä¸ºæ‰€æœ‰å›¾ç‰‡çš„æ ‡ç­¾æ•°å­—åˆ—è¡¨ã€‚
è€ƒè™‘åˆ° map å‡½æ•°çš„ä½ç½®ä¸º db = db.shuffle(1000).map(preprocess).batch(32)ï¼Œé‚£ä¹ˆpreprocess çš„ä¼ å…¥å‚æ•°ä¸º(ğ‘¥ğ‘–, ğ‘¦ğ‘–)ï¼Œ
å…¶ä¸­ğ‘¥ğ‘–å’Œğ‘¦ğ‘–åˆ†åˆ«ä¸ºç¬¬ğ‘–ä¸ªå›¾ç‰‡çš„è·¯å¾„å­—ç¬¦ä¸²å’Œæ ‡ç­¾æ•°å­—ã€‚å¦‚ æœ map å‡½æ•°çš„ä½ç½®ä¸º db = db.shuffle(1000).batch(32) .map(preprocess)ï¼Œ
é‚£ä¹ˆ preprocess çš„ä¼ å…¥å‚æ•°ä¸º(ğ’™ğ‘–, ğ’šğ‘–)ï¼Œå…¶ä¸­ğ’™ğ‘–å’Œğ’šğ‘–åˆ†åˆ«ä¸ºç¬¬ğ‘–ä¸ª Batch çš„è·¯å¾„å’Œæ ‡ç­¾åˆ—è¡¨ã€‚
ä»£ç å¦‚ä¸‹ï¼š
def preprocess(x,y): # é¢„å¤„ç†å‡½æ•°
    # x: å›¾ç‰‡çš„è·¯å¾„ï¼Œyï¼šå›¾ç‰‡çš„æ•°å­—ç¼–ç 
    x = tf.io.read_file(x) # æ ¹æ®è·¯å¾„è¯»å–å›¾ç‰‡
    x = tf.image.decode_jpeg(x, channels=3) # å›¾ç‰‡è§£ç ï¼Œå¿½ç•¥é€æ˜é€šé“
    x = tf.image.resize(x, [244, 244]) # å›¾ç‰‡ç¼©æ”¾ä¸ºç•¥å¤§äº 224 çš„ 244
    # æ•°æ®å¢å¼ºï¼Œè¿™é‡Œå¯ä»¥è‡ªç”±ç»„åˆå¢å¼ºæ‰‹æ®µ
    # x = tf.image.random_flip_up_down(x)
    x = tf.image.random_flip_left_right(x) # å·¦å³é•œåƒ
    x = tf.image.random_crop(x, [224, 224, 3]) # éšæœºè£å‰ªä¸º 224
    # è½¬æ¢æˆå¼ é‡ï¼Œå¹¶å‹ç¼©åˆ° 0~1 åŒºé—´
    # x: [0,255]=> 0~1
    x = tf.cast(x, dtype=tf.float32) / 255. # 0~1 => D(0,1)
    x = normalize(x) # æ ‡å‡†åŒ–
    y = tf.convert_to_tensor(y) # è½¬æ¢æˆå¼ é‡

    return x, y

è€ƒè™‘åˆ°æˆ‘ä»¬çš„æ•°æ®é›†è§„æ¨¡éå¸¸å°ï¼Œä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæˆ‘ä»¬åšäº†å°‘é‡çš„æ•°æ®å¢å¼ºå˜æ¢ï¼Œä»¥è·å¾—æ›´å¤šæ ·å¼çš„å›¾ç‰‡æ•°æ®ã€‚æœ€åæˆ‘ä»¬å°† 0~255 èŒƒå›´çš„åƒç´ å€¼ç¼©æ”¾åˆ° 0~1 èŒƒå›´ï¼Œ
å¹¶é€šè¿‡æ ‡å‡†åŒ–å‡½æ•° normalize å®ç°æ•°æ®çš„æ ‡å‡†åŒ–è¿ç®—ï¼Œå°†åƒç´ æ˜ å°„ä¸º 0 å‘¨å›´åˆ†å¸ƒï¼Œæœ‰åˆ©äºç½‘ç»œçš„ä¼˜åŒ–ã€‚æœ€åå°†æ•°æ®è½¬æ¢ä¸ºå¼ é‡æ•°æ®è¿”å›ã€‚
æ­¤æ—¶å¯¹ db å¯¹è±¡è¿­ä»£æ—¶è¿”å›çš„æ•°æ®å°†æ˜¯æ‰¹é‡å½¢å¼çš„å›¾ç‰‡å¼ é‡æ•°æ®å’Œæ ‡ç­¾å¼ é‡ã€‚

æ ‡å‡†åŒ–åçš„æ•°æ®é€‚åˆç½‘ç»œçš„è®­ç»ƒåŠé¢„æµ‹ï¼Œä½†æ˜¯åœ¨è¿›è¡Œå¯è§†åŒ–æ—¶ï¼Œéœ€è¦å°†æ•°æ®æ˜ å°„å›0~1 çš„èŒƒå›´ã€‚å®ç°æ ‡å‡†åŒ–å’Œæ ‡å‡†åŒ–çš„é€†è¿‡ç¨‹å¦‚ä¸‹ï¼š
# è¿™é‡Œçš„ mean å’Œ std æ ¹æ®çœŸå®çš„æ•°æ®è®¡ç®—è·å¾—ï¼Œæ¯”å¦‚ ImageNet
img_mean = tf.constant([0.485, 0.456, 0.406])
img_std = tf.constant([0.229, 0.224, 0.225])

    def normalize(x, mean=img_mean, std=img_std):
    # æ ‡å‡†åŒ–å‡½æ•°
    # x: [224, 224, 3]
    # mean: [224, 224, 3], std: [3]
    x = (x - mean)/std
    return x

def denormalize(x, mean=img_mean, std=img_std):
    # æ ‡å‡†åŒ–çš„é€†è¿‡ç¨‹å‡½æ•°
    x = x * std + mean
    return x

ä½¿ç”¨ä¸Šè¿°æ–¹æ³•ï¼Œåˆ†å¸ƒåˆ›å»ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†çš„ Dataset å¯¹è±¡ã€‚ä¸€èˆ¬æ¥è¯´ï¼ŒéªŒè¯é›†å’Œæµ‹è¯•é›†å¹¶ä¸ç›´æ¥å‚ä¸ç½‘ç»œå‚æ•°çš„ä¼˜åŒ–ï¼Œå¹¶ä¸éœ€è¦éšæœºæ‰“æ•£æ ·æœ¬æ¬¡åºã€‚
ä»£ç å¦‚ä¸‹ï¼š
batchsz = 128
# åˆ›å»ºè®­ç»ƒé›† Dataset å¯¹è±¡
images, labels, table = load_pokemon('pokemon',mode='train')
db_train = tf.data.Dataset.from_tensor_slices((images, labels))
db_train = db_train.shuffle(1000).map(preprocess).batch(batchsz)
# åˆ›å»ºéªŒè¯é›† Dataset å¯¹è±¡
images2, labels2, table = load_pokemon('pokemon',mode='val')
db_val = tf.data.Dataset.from_tensor_slices((images2, labels2))
db_val = db_val.map(preprocess).batch(batchsz)
# åˆ›å»ºæµ‹è¯•é›† Dataset å¯¹è±¡
images3, labels3, table = load_pokemon('pokemon',mode='test')
db_test = tf.data.Dataset.from_tensor_slices((images3, labels3))
db_test = db_test.map(preprocess).batch(batchsz)


15.3.3åˆ›å»ºæ¨¡å‹
å‰é¢å·²ç»ä»‹ç»å¹¶å®ç°äº† VGG13 å’Œ ResNet18 ç­‰ä¸»æµç½‘ç»œæ¨¡å‹ï¼Œè¿™é‡Œæˆ‘ä»¬å°±ä¸å†èµ˜è¿°æ¨¡å‹çš„å…·ä½“å®ç°ç»†èŠ‚ã€‚
åœ¨ keras.applications æ¨¡å—ä¸­å®ç°äº†å¸¸ç”¨çš„ç½‘ç»œæ¨¡å‹ï¼Œå¦‚ VGG ç³»åˆ—ã€ ResNet ç³»åˆ—ã€DenseNet ç³»åˆ—ã€MobileNet ç³»åˆ—ç­‰ç­‰ï¼Œ
åªéœ€è¦ä¸€è¡Œä»£ç å³å¯åˆ›å»ºè¿™äº›æ¨¡å‹ç½‘ç»œã€‚ä¾‹å¦‚ï¼š
# åŠ è½½ DenseNet ç½‘ç»œæ¨¡å‹ï¼Œå¹¶å»æ‰æœ€åä¸€å±‚å…¨è¿æ¥å±‚ï¼Œæœ€åä¸€ä¸ªæ± åŒ–å±‚è®¾ç½®ä¸º max pooling
net = keras.applications.DenseNet121(include_top=False, pooling='max')
# è®¾ç½®ä¸º Trueï¼Œå³ DenseNet éƒ¨åˆ†çš„å‚æ•°ä¹Ÿå‚ä¸ä¼˜åŒ–æ›´æ–°
net.trainable = True

newnet = keras.Sequential([
    net, # å»æ‰æœ€åä¸€å±‚çš„ DenseNet121
    layers.Dense(1024, activation='relu'), # è¿½åŠ å…¨è¿æ¥å±‚
    layers.BatchNormalization(), # è¿½åŠ  BN å±‚
    layers.Dropout(rate=0.5), # è¿½åŠ  Dropout å±‚ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
    layers.Dense(5) # æ ¹æ®å®å¯æ¢¦æ•°æ®çš„ç±»åˆ«æ•°ï¼Œè®¾ç½®æœ€åä¸€å±‚è¾“å‡ºèŠ‚ç‚¹æ•°ä¸º 5
])
newnet.build(input_shape=(4,224,224,3))
newnet.summary()

ä¸Šé¢ä½¿ç”¨ DenseNet121 æ¨¡å‹æ¥åˆ›å»ºç½‘ç»œï¼Œç”±äº DenseNet121 çš„æœ€åä¸€å±‚è¾“å‡ºèŠ‚ç‚¹è®¾è®¡ä¸º1000ï¼Œæˆ‘ä»¬å°† DenseNet121 å»æ‰æœ€åä¸€å±‚ï¼Œ
å¹¶æ ¹æ®è‡ªå®šä¹‰æ•°æ®é›†çš„ç±»åˆ«æ•°ï¼Œæ·»åŠ ä¸€ä¸ªè¾“å‡ºèŠ‚ç‚¹æ•°ä¸º 5 çš„å…¨è¿æ¥å±‚ï¼Œé€šè¿‡ Sequential å®¹å™¨é‡æ–°åŒ…è£¹æˆæ–°çš„ç½‘ç»œæ¨¡å‹ã€‚
å…¶ä¸­include_top=False è¡¨æ˜å»æ‰æœ€åçš„å…¨è¿æ¥å±‚ï¼Œpooling='max'è¡¨ç¤º DenseNet121 æœ€åä¸€ä¸ªPooling å±‚è®¾è®¡ä¸º Max Pollingã€‚
ç½‘ç»œæ¨¡å‹ç»“æ„å›¾ 15.4 æ‰€ç¤ºã€‚

15.3.4ç½‘ç»œæµ‹è¯•ä¸è®­ç»ƒ
æˆ‘ä»¬ç›´æ¥ä½¿ç”¨ Keras æä¾›çš„ Compile&Fit æ–¹å¼è£…é…å¹¶è®­ç»ƒç½‘ç»œï¼Œä¼˜åŒ–å™¨é‡‡ç”¨æœ€å¸¸ç”¨çš„Adam ä¼˜åŒ–å™¨ï¼Œè¯¯å·®å‡½æ•°é‡‡ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œ
å¹¶è®¾ç½® from_logits=Trueï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å…³æ³¨çš„æµ‹é‡æŒ‡æ ‡ä¸ºå‡†ç¡®ç‡ã€‚ç½‘ç»œæ¨¡å‹è£…é…ä»£ç å¦‚ä¸‹ï¼š
# è£…é…æ¨¡å‹
newnet.compile(optimizer=optimizers.Adam(lr=1e-3),
               loss=losses.CategoricalCrossentropy(from_logits=True),
               metrics=['accuracy'])
é€šè¿‡ fit å‡½æ•°åœ¨è®­ç»ƒé›†ä¸Šé¢è®­ç»ƒæ¨¡å‹ï¼Œæ¯è¿­ä»£ä¸€ä¸ª Epoch æµ‹è¯•ä¸€æ¬¡éªŒè¯é›†ï¼Œæœ€å¤§è®­ç»ƒEpoch æ•°ä¸º 100ï¼Œä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæˆ‘ä»¬é‡‡ç”¨äº† Early Stopping æŠ€æœ¯ï¼Œ
åœ¨ fit å‡½æ•°çš„ callbackså‚æ•°ä¸­ä¼ å…¥ Early Stopping ç±»å®ä¾‹ã€‚
ä»£ç å¦‚ä¸‹ï¼š
# è®­ç»ƒæ¨¡å‹ï¼Œæ”¯æŒ early stopping
history = newnet.fit(db_train, validation_data=db_val, validation_freq=1, epochs=100, callbacks=[early_stopping])
å…¶ä¸­ early_stopping ä¸ºæ ‡å‡†çš„ EarlyStopping ç±»ï¼Œå®ƒç›‘å¬çš„æŒ‡æ ‡æ˜¯éªŒè¯é›†å‡†ç¡®ç‡ï¼Œå¦‚æœè¿ç»­ä¸‰æ¬¡éªŒè¯é›†çš„æµ‹é‡ç»“æœæ²¡æœ‰æå‡ 0.001ï¼Œ
åˆ™è§¦å‘ EarlyStopping æ¡ä»¶ï¼Œè®­ç»ƒç»“æŸã€‚ä»£ç å¦‚ä¸‹ï¼š

# åˆ›å»º Early Stopping ç±»ï¼Œè¿ç»­ 3 æ¬¡ä¸ä¸Šå‡åˆ™ç»ˆæ­¢è®­ç»ƒ
early_stopping = EarlyStopping(
    monitor='val_accuracy',
    min_delta=0.001,
    patience=3
)
æˆ‘ä»¬å°†è®­ç»ƒè¿‡ç¨‹ä¸­çš„è®­ç»ƒå‡†ç¡®ç‡ã€éªŒè¯å‡†ç¡®ç‡ä»¥åŠæœ€åæµ‹è¯•é›†ä¸Šé¢è·å¾—çš„å‡†ç¡®ç‡ç»˜åˆ¶ä¸ºæ›²çº¿ï¼Œå¦‚å›¾ 15.5 æ‰€ç¤ºã€‚å¯ä»¥çœ‹åˆ°ï¼Œè®­ç»ƒå‡†ç¡®ç‡è¿…é€Ÿæå‡å¹¶ç»´æŒåœ¨è¾ƒé«˜çŠ¶æ€ï¼Œ
ä½†æ˜¯éªŒè¯å‡†ç¡®ç‡æ¯”è¾ƒå·®ï¼ŒåŒæ—¶å¹¶æ²¡æœ‰è·å¾—è¾ƒå¤§æå‡ï¼ŒEarly Stopping æ¡ä»¶ç²—å‘ï¼Œè®­ç»ƒå¾ˆå¿«ç»ˆæ­¢ï¼Œç½‘ç»œå‡ºç°äº†éå¸¸ä¸¥é‡çš„è¿‡æ‹Ÿåˆç°è±¡ã€‚

é‚£ä¹ˆä¸ºä»€ä¹ˆä¼šå‡ºç°è¿‡æ‹Ÿåˆç°è±¡å‘¢ï¼Ÿè€ƒè™‘æˆ‘ä»¬ä½¿ç”¨çš„ DensetNet121 æ¨¡å‹çš„å±‚æ•°è¾¾åˆ°äº†121 å±‚ï¼Œå‚æ•°é‡è¾¾åˆ°äº† 7M ä¸ªï¼Œæ˜¯æ¯”è¾ƒå¤§å‹çš„ç½‘ç»œæ¨¡å‹ï¼Œ
è€Œæˆ‘ä»¬å¤§æ•°æ®é›†ä»…æœ‰çº¦ 1000 ä¸ªæ ·æœ¬ã€‚æ ¹æ®ç»éªŒï¼Œè¿™è¿œè¿œä¸è¶³ä»¥è®­ç»ƒå¥½å¦‚æ­¤å¤§è§„æ¨¡çš„ç½‘ç»œæ¨¡å‹ï¼Œæå…¶å®¹æ˜“å‡ºç°è¿‡æ‹Ÿåˆç°è±¡ã€‚
ä¸ºäº†å‡è½»è¿‡æ‹Ÿåˆï¼Œå¯ä»¥é‡‡ç”¨å±‚æ•°æ›´æµ…ã€å‚æ•°é‡æ›´å°‘çš„ç½‘ç»œæ¨¡å‹ï¼Œæˆ–è€…æ·»åŠ æ­£åˆ™åŒ–é¡¹ï¼Œç”šè‡³å¢åŠ æ•°æ®é›†çš„è§„æ¨¡ç­‰ã€‚
é™¤äº†è¿™äº›æ–¹å¼ä»¥å¤–ï¼Œå¦å¤–ä¸€ç§è¡Œä¹‹æœ‰æ•ˆçš„æ–¹å¼å°±æ˜¯è¿ç§»å­¦ä¹ æŠ€æœ¯ã€‚

"""