# å½“å‰ç‰ˆæœ¬ ï¼š python3.7.11
# å¼€å‘æ—¶é—´ ï¼š 2021/9/17 16:29
"""
æœ¬èŠ‚æˆ‘ä»¬å°†åˆ©ç”¨å…¨è¿æ¥ç½‘ç»œæ¨¡å‹æ¥å®Œæˆæ±½è½¦çš„æ•ˆèƒ½æŒ‡æ ‡ MPG(Mile Per Gallonï¼Œæ¯åŠ ä»‘ç‡ƒæ²¹è‹±é‡Œæ•°)çš„é¢„æµ‹é—®é¢˜å®æˆ˜ã€‚

6.8.1æ•°æ®é›†
æˆ‘ä»¬é‡‡ç”¨ Auto MPG æ•°æ®é›†ï¼Œå®ƒè®°å½•äº†å„ç§æ±½è½¦æ•ˆèƒ½æŒ‡æ ‡ä¸æ°”ç¼¸æ•°ã€é‡é‡ã€é©¬åŠ›ç­‰å…¶å®ƒå› å­çš„çœŸå®æ•°æ®ï¼ŒæŸ¥çœ‹æ•°æ®é›†çš„å‰ 5 é¡¹ï¼Œå¦‚è¡¨ 6.1 æ‰€ç¤ºï¼Œ
å…¶ä¸­æ¯ä¸ªå­—æ®µçš„å«ä¹‰åˆ—åœ¨è¡¨ 6.2 ä¸­ã€‚é™¤äº†äº§åœ°çš„æ•°å­—å­—æ®µè¡¨ç¤ºç±»åˆ«å¤–ï¼Œå…¶ä»–å­—æ®µéƒ½æ˜¯æ•°å€¼ç±»å‹ã€‚å¯¹äºäº§åœ°åœ°æ®µï¼Œ1 è¡¨ç¤ºç¾å›½ï¼Œ2 è¡¨ç¤ºæ¬§æ´²ï¼Œ3 è¡¨ç¤ºæ—¥æœ¬ã€‚
                            è¡¨ 6.1 Auto MPG æ•°æ®é›†å‰ 5 é¡¹
MPG    Cylinders    Displacement     Horsepower    Weight   Acceleration   ModelYear   Origin
18.0      8             307.0          130.0       3504.0      12.0            70        1
15.0      8             350.0          165.0       3693.0      11.5            70        1
18.0      8             318.0          150.0       3436.0      11.0            70        1
16.0      8             304.0          150.0       3433.0      12.0            70        1
17.0      8             302.0          140.0       3449.0      10.5            70        1
                           è¡¨ 6.2 æ•°æ®é›†å­—æ®µå«ä¹‰
MPG    Cylinders    Displacement    Horsepower     Weight    Acceleration   ModelYear   Origin
æ¯åŠ ä»‘  æ°”ç¼¸æ•°           æ’é‡          é©¬åŠ›         é‡é‡        åŠ é€Ÿåº¦       å‹å·å¹´ä»½    äº§åœ°
ç‡ƒæ²¹
è‹±é‡Œ

Auto MPG æ•°æ®é›†ä¸€å…±è®°å½•äº† 398 é¡¹æ•°æ®ï¼Œæˆ‘ä»¬ä» UCI æœåŠ¡å™¨ä¸‹è½½å¹¶è¯»å–æ•°æ®é›†åˆ°DataFrame å¯¹è±¡ä¸­ï¼Œä»£ç å¦‚ä¸‹ï¼š
# åœ¨çº¿ä¸‹è½½æ±½è½¦æ•ˆèƒ½æ•°æ®é›†
dataset_path = keras.utils.get_file("auto-mpg.data",
"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data")
# åˆ©ç”¨ pandas è¯»å–æ•°æ®é›†ï¼Œå­—æ®µæœ‰æ•ˆèƒ½ï¼ˆå…¬é‡Œæ•°æ¯åŠ ä»‘ï¼‰ï¼Œæ°”ç¼¸æ•°ï¼Œæ’é‡ï¼Œé©¬åŠ›ï¼Œé‡é‡
# åŠ é€Ÿåº¦ï¼Œå‹å·å¹´ä»½ï¼Œäº§åœ°
column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight','Acceleration', 'Model Year', 'Origin']
raw_dataset = pd.read_csv(dataset_path, names=column_names,na_values = "?", comment='\t',sep=" ", skipinitialspace=True)
dataset = raw_dataset.copy()
# æŸ¥çœ‹éƒ¨åˆ†æ•°æ®
dataset.head()
åŸå§‹è¡¨æ ¼ä¸­çš„æ•°æ®å¯èƒ½å«æœ‰ç©ºå­—æ®µ(ç¼ºå¤±å€¼)çš„æ•°æ®é¡¹ï¼Œéœ€è¦æ¸…é™¤è¿™äº›è®°å½•é¡¹ï¼š
dataset.isna().sum() # ç»Ÿè®¡ç©ºç™½æ•°æ®
dataset = dataset.dropna() # åˆ é™¤ç©ºç™½æ•°æ®é¡¹
dataset.isna().sum() # å†æ¬¡ç»Ÿè®¡ç©ºç™½æ•°æ®
æ¸…é™¤åï¼Œè§‚å¯Ÿåˆ°æ•°æ®é›†è®°å½•é¡¹å‡ä¸º 392 é¡¹ã€‚
ç”±äº Origin å­—æ®µä¸ºç±»åˆ«ç±»å‹æ•°æ®ï¼Œæˆ‘ä»¬å°†å…¶ç§»é™¤ï¼Œå¹¶è½¬æ¢ä¸ºæ–°çš„ 3 ä¸ªå­—æ®µï¼šUSAã€ Europe å’Œ Japanï¼Œåˆ†åˆ«ä»£è¡¨æ˜¯å¦æ¥è‡ªæ­¤äº§åœ°ï¼š
# å¤„ç†ç±»åˆ«å‹æ•°æ®ï¼Œå…¶ä¸­ origin åˆ—ä»£è¡¨äº†ç±»åˆ« 1,2,3,åˆ†å¸ƒä»£è¡¨äº§åœ°ï¼šç¾å›½ã€æ¬§æ´²ã€æ—¥æœ¬
# å…ˆå¼¹å‡º(åˆ é™¤å¹¶è¿”å›)origin è¿™ä¸€åˆ—
origin = dataset.pop('Origin')
# æ ¹æ® origin åˆ—æ¥å†™å…¥æ–°çš„ 3 ä¸ªåˆ—
dataset['USA'] = (origin == 1)*1.0
dataset['Europe'] = (origin == 2)*1.0
dataset['Japan'] = (origin == 3)*1.0
dataset.tail() # æŸ¥çœ‹æ–°è¡¨æ ¼çš„åå‡ é¡¹
æŒ‰ç€ 8:2 çš„æ¯”ä¾‹åˆ‡åˆ†æ•°æ®é›†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼š
# åˆ‡åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†
train_dataset = dataset.sample(frac=0.8,random_state=0)
test_dataset = dataset.drop(train_dataset.index)
å°† MPG å­—æ®µç§»å‡ºä¸ºæ ‡ç­¾æ•°æ®ï¼š
# ç§»åŠ¨ MPG æ²¹è€—æ•ˆèƒ½è¿™ä¸€åˆ—ä¸ºçœŸå®æ ‡ç­¾ Y
train_labels = train_dataset.pop('MPG')
test_labels = test_dataset.pop('MPG')
ç»Ÿè®¡è®­ç»ƒé›†çš„å„ä¸ªå­—æ®µæ•°å€¼çš„å‡å€¼å’Œæ ‡å‡†å·®ï¼Œå¹¶å®Œæˆæ•°æ®çš„æ ‡å‡†åŒ–ï¼Œé€šè¿‡ norm()å‡½æ•°
å®ç°ï¼Œä»£ç å¦‚ä¸‹ï¼š
# æŸ¥çœ‹è®­ç»ƒé›†çš„è¾“å…¥ X çš„ç»Ÿè®¡æ•°æ®
train_stats = train_dataset.describe()
train_stats.pop("MPG") # ä»…ä¿ç•™è¾“å…¥ X
train_stats = train_stats.transpose() # è½¬ç½®
# æ ‡å‡†åŒ–æ•°æ®
def norm(x): # å‡å»æ¯ä¸ªå­—æ®µçš„å‡å€¼ï¼Œå¹¶é™¤ä»¥æ ‡å‡†å·®
 return (x - train_stats['mean']) / train_stats['std']
normed_train_data = norm(train_dataset) # æ ‡å‡†åŒ–è®­ç»ƒé›†
normed_test_data = norm(test_dataset) # æ ‡å‡†åŒ–æµ‹è¯•é›†
æ‰“å°å‡ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„å¤§å°ï¼š
print(normed_train_data.shape,train_labels.shape)
print(normed_test_data.shape, test_labels.shape)
(314, 9) (314,) # è®­ç»ƒé›†å…± 314 è¡Œï¼Œè¾“å…¥ç‰¹å¾é•¿åº¦ä¸º 9,æ ‡ç­¾ç”¨ä¸€ä¸ªæ ‡é‡è¡¨ç¤º
(78, 9) (78,) # æµ‹è¯•é›†å…± 78 è¡Œï¼Œè¾“å…¥ç‰¹å¾é•¿åº¦ä¸º 9,æ ‡ç­¾ç”¨ä¸€ä¸ªæ ‡é‡è¡¨ç¤ºåˆ©ç”¨åˆ‡åˆ†çš„è®­ç»ƒé›†æ•°æ®æ„å»ºæ•°æ®é›†å¯¹è±¡ï¼š
train_db = tf.data.Dataset.from_tensor_slices((normed_train_data.values,
train_labels.values)) # æ„å»º Dataset å¯¹è±¡
train_db = train_db.shuffle(100).batch(32) # éšæœºæ‰“æ•£ï¼Œæ‰¹é‡åŒ–

æˆ‘ä»¬å¯ä»¥é€šè¿‡ç®€å•åœ°ç»Ÿè®¡æ•°æ®é›†ä¸­å„å­—æ®µä¹‹é—´çš„ä¸¤ä¸¤åˆ†å¸ƒæ¥è§‚å¯Ÿå„ä¸ªå­—æ®µå¯¹ MPG çš„å½±å“ï¼Œå¦‚å›¾ 6.16 æ‰€ç¤ºã€‚
å¯ä»¥å¤§è‡´è§‚å¯Ÿåˆ°ï¼Œå…¶ä¸­æ±½è½¦æ’é‡ã€é‡é‡ä¸ MPG çš„å…³ç³»æ¯”è¾ƒç®€å•ï¼Œéšç€æ’é‡æˆ–é‡é‡çš„å¢å¤§ï¼Œæ±½è½¦çš„ MPG é™ä½ï¼Œèƒ½è€—å¢åŠ ï¼›
æ°”ç¼¸æ•°è¶Šå°ï¼Œæ±½è½¦èƒ½åšåˆ°çš„æœ€å¥½MPG ä¹Ÿè¶Šé«˜ï¼Œè¶Šå¯èƒ½æ›´èŠ‚èƒ½ï¼Œè¿™éƒ½æ˜¯æ˜¯ç¬¦åˆæˆ‘ä»¬çš„ç”Ÿæ´»ç»éªŒçš„ã€‚


6.8.2åˆ›å»ºç½‘ç»œ
è€ƒè™‘åˆ° Auto MPG æ•°æ®é›†è§„æ¨¡è¾ƒå°ï¼Œæˆ‘ä»¬åªåˆ›å»ºä¸€ä¸ª 3 å±‚çš„å…¨è¿æ¥ç½‘ç»œæ¥å®Œæˆ MPGå€¼çš„é¢„æµ‹ä»»åŠ¡ã€‚
è¾“å…¥ğ‘¿çš„ç‰¹å¾å…±æœ‰ 9 ç§ï¼Œå› æ­¤ç¬¬ä¸€å±‚çš„è¾“å…¥èŠ‚ç‚¹æ•°ä¸º 9ã€‚ç¬¬ä¸€å±‚ã€ç¬¬äºŒå±‚çš„è¾“å‡ºèŠ‚ç‚¹æ•°è®¾è®¡ä¸º64å’Œ64ï¼Œç”±äºåªæœ‰ä¸€ç§é¢„æµ‹å€¼ï¼Œ
è¾“å‡ºå±‚è¾“å‡ºèŠ‚ç‚¹è®¾è®¡ä¸º 1ã€‚è€ƒè™‘MPG âˆˆ ğ‘…+ï¼Œå› æ­¤è¾“å‡ºå±‚çš„æ¿€æ´»å‡½æ•°å¯ä»¥ä¸åŠ ï¼Œä¹Ÿå¯ä»¥æ·»åŠ  ReLU æ¿€æ´»å‡½æ•°ã€‚

æˆ‘ä»¬å°†ç½‘ç»œå®ç°ä¸ºä¸€ä¸ªè‡ªå®šä¹‰ç½‘ç»œç±»ï¼Œåªéœ€è¦åœ¨åˆå§‹åŒ–å‡½æ•°ä¸­åˆ›å»ºå„ä¸ªå­ç½‘ç»œå±‚ï¼Œå¹¶åœ¨å‰å‘è®¡ç®—å‡½æ•° call ä¸­å®ç°è‡ªå®šä¹‰ç½‘ç»œç±»çš„è®¡ç®—é€»è¾‘å³å¯ã€‚
è‡ªå®šä¹‰ç½‘ç»œç±»ç»§æ‰¿è‡ªkeras.Model åŸºç±»ï¼Œè¿™ä¹Ÿæ˜¯è‡ªå®šä¹‰ç½‘ç»œç±»çš„æ ‡å‡†å†™æ³•ï¼Œä»¥æ–¹ä¾¿åœ°åˆ©ç”¨ keras.Model åŸºç±»æä¾›çš„ trainable_variablesã€save_weights
ç­‰å„ç§ä¾¿æ·åŠŸèƒ½ã€‚ç½‘ç»œæ¨¡å‹ç±»å®ç°å¦‚ä¸‹ï¼š
class Network(keras.Model):
    # å›å½’ç½‘ç»œæ¨¡å‹
    def __init__(self):
        super(Network, self).__init__()
        # åˆ›å»º 3 ä¸ªå…¨è¿æ¥å±‚
        self.fc1 = layers.Dense(64, activation='relu')
        self.fc2 = layers.Dense(64, activation='relu')
        self.fc3 = layers.Dense(1)

    def call(self, inputs, training=None, mask=None):
        # ä¾æ¬¡é€šè¿‡ 3 ä¸ªå…¨è¿æ¥å±‚
        x = self.fc1(inputs)
        x = self.fc2(x)
        x = self.fc3(x)

        return x


6.8.3è®­ç»ƒä¸æµ‹è¯•
åœ¨å®Œæˆä¸»ç½‘ç»œæ¨¡å‹ç±»çš„åˆ›å»ºåï¼Œæˆ‘ä»¬æ¥å®ä¾‹åŒ–ç½‘ç»œå¯¹è±¡å’Œåˆ›å»ºä¼˜åŒ–å™¨ï¼Œä»£ç å¦‚ä¸‹ï¼š
model = Network() # åˆ›å»ºç½‘ç»œç±»å®ä¾‹
# é€šè¿‡ build å‡½æ•°å®Œæˆå†…éƒ¨å¼ é‡çš„åˆ›å»ºï¼Œå…¶ä¸­ 4 ä¸ºä»»æ„è®¾ç½®çš„ batch æ•°é‡ï¼Œ9 ä¸ºè¾“å…¥ç‰¹å¾é•¿åº¦
model.build(input_shape=(4, 9))
model.summary() # æ‰“å°ç½‘ç»œä¿¡æ¯
optimizer = tf.keras.optimizers.RMSprop(0.001) # åˆ›å»ºä¼˜åŒ–å™¨ï¼ŒæŒ‡å®šå­¦ä¹ ç‡
æ¥ä¸‹æ¥å®ç°ç½‘ç»œè®­ç»ƒéƒ¨åˆ†ã€‚é€šè¿‡ Epoch å’Œ Step ç»„æˆçš„åŒå±‚å¾ªç¯è®­ç»ƒç½‘ç»œï¼Œå…±è®­ç»ƒ 200ä¸ª Epochï¼Œä»£ç å¦‚ä¸‹:
for epoch in range(200): # 200 ä¸ª Epoch
     for step, (x,y) in enumerate(train_db): # éå†ä¸€æ¬¡è®­ç»ƒé›†
         # æ¢¯åº¦è®°å½•å™¨ï¼Œè®­ç»ƒæ—¶éœ€è¦ä½¿ç”¨å®ƒ
         with tf.GradientTape() as tape:
         out = model(x) # é€šè¿‡ç½‘ç»œè·å¾—è¾“å‡º
         loss = tf.reduce_mean(losses.MSE(y, out)) # è®¡ç®— MSE
         mae_loss = tf.reduce_mean(losses.MAE(y, out)) # è®¡ç®— MAE
         if step % 10 == 0: # é—´éš”æ€§åœ°æ‰“å°è®­ç»ƒè¯¯å·®
         print(epoch, step, float(loss))
         # è®¡ç®—æ¢¯åº¦ï¼Œå¹¶æ›´æ–°
         grads = tape.gradient(loss, model.trainable_variables)
         optimizer.apply_gradients(zip(grads, model.trainable_variables))


å¯¹äºå›å½’é—®é¢˜ï¼Œé™¤äº† MSE å‡æ–¹å·®å¯ä»¥ç”¨æ¥æ¨¡å‹çš„æµ‹è¯•æ€§èƒ½ï¼Œè¿˜å¯ä»¥ç”¨å¹³å‡ç»å¯¹è¯¯å·®(Mean Absolute Errorï¼Œç®€ç§° MAE)æ¥è¡¡é‡æ¨¡å‹çš„æ€§èƒ½ï¼Œ
å®ƒè¢«å®šä¹‰ä¸ºï¼š
                mae â‰œ 1 / ğ‘‘out âˆ‘ğ‘– |ğ‘¦ğ‘– âˆ’ ğ‘œğ‘–|
ç¨‹åºè¿ç®—æ—¶è®°å½•æ¯ä¸ª Epoch ç»“æŸæ—¶çš„è®­ç»ƒå’Œæµ‹è¯• MAE æ•°æ®ï¼Œå¹¶ç»˜åˆ¶å˜åŒ–æ›²çº¿ï¼Œå¦‚å›¾ 6.17æ‰€ç¤ºã€‚

å¯ä»¥è§‚å¯Ÿåˆ°ï¼Œåœ¨è®­ç»ƒåˆ°çº¦ç¬¬ 25 ä¸ª Epoch æ—¶ï¼ŒMAE çš„ä¸‹é™å˜å¾—è¾ƒç¼“æ…¢ï¼Œå…¶ä¸­è®­ç»ƒé›†çš„ MAEè¿˜åœ¨ç»§ç»­ç¼“æ…¢ä¸‹é™ï¼Œä½†æ˜¯æµ‹è¯•é›† MAE å‡ ä¹ä¿æŒä¸å˜ï¼Œ
å› æ­¤å¯ä»¥åœ¨çº¦ç¬¬ 25 ä¸ª epoch æ—¶æå‰ç»“æŸè®­ç»ƒï¼Œå¹¶åˆ©ç”¨æ­¤æ—¶çš„ç½‘ç»œå‚æ•°æ¥é¢„æµ‹æ–°çš„è¾“å…¥æ ·æœ¬å³å¯ã€‚
"""