# 当前版本 ： python3.7.11
# 开发时间 ： 2021/9/22 16:08
"""
首先我们来分析全连接网络存在的问题。考虑一个简单的 4 层全连接层网络，输入是 28 × 28打平后为 784 节点的手写数字图片向量，
中间三个隐藏层的节点数都是 256，输出层的节点数是 10，如图 10.1 所示。

通过 TensorFlow 快速地搭建此网络模型，添加 4 个 Dense 层，并使用 Sequential 容器
封装为一个网络对象：
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers,Sequential,losses,optimizers,datasets
# 创建 4 层全连接网络
model = keras.Sequential([
layers.Dense(256, activation='relu'),
layers.Dense(256, activation='relu'),
layers.Dense(256, activation='relu'),
layers.Dense(10),
])
# build 模型，并打印模型信息
model.build(input_shape=(4, 784))
model.summary()

利用 summary()函数打印出模型每一层的参数量统计结果，如表 10.1 所示。网络的参数量是怎么计算的呢？对于每一条连接线的权值标量，
视作一个参数，因此对输入节点数为 𝑛，输出节点数为𝑚的全连接层来说，𝑾张量包含的参数量共有𝑛 ∙ 𝑚个，𝒃向量包含的参数量有𝑚个，
则全连接层的总参数量为𝑛 ∙ 𝑚 + 𝑚。以第一层为例，输入特征长度为 784，输 出特征长度为 256，当前层的参数量为 8 ∙ 2 + 2 = 2 9 ，
同样的方法可以计算第二、三、四层的参数量分别为： 92、 92、2 ，总参数量约 34 万个。在计算机中，如果将单个权值保存为 float 类型的变量，
至少需要占用 4 个字节内存(Python 语言中float 占用内存更多)，那么 34 万个网络参数至少需要约 1.34MB 内存。也就是说，
单就存储网络的参数就需要 1.34MB 内存，实际上，网络的训练过程中还需要缓存计算图模型、梯度信息、输入和中间计算结果等，
其中梯度相关运算占用资源非常多。

那么训练这样一个网络到底需要多少内存呢？我们可以在现代 GPU 设备上简单模拟一下资源消耗情况。
在 TensorFlow 中，如果不设置显存占用方式，那么默认会占用全部显存。这里将 TensorFlow 的显存使用方式设置为按需分配，
观测其真实占用的 GPU 显存资源情况，代码如下：
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
    except RuntimeError as e:
        print(e)

上述代码插入在 TensorFlow 库导入后、模型创建前的位置，通过tf.config.experimental.set_memory_growth(gpu, True)设置 TensorFlow 按需申请显存资源，
这样 TensorFlow 占用的显存大小即为运算需要的数量。在 Batch Size 设置为 32 的情况下，x训练时我们观察到显存占用了约 708MB，
内存占用约 870MB。由于现代深度学习框架设计考量不一样，这个数字仅做参考。即便如此，我们也能感受到 4 层的全连接层的计算代价并不小。

回到 1980 年代，1.3MB 的网络参数量是什么概念呢？1989 年，Yann LeCun 在手写邮政编码识别的论文 [2]中采用了一台 256KB 内存的计算机实现了他的算法，
这台计算机还配备了一块 AT&T DSP-32C 的 DSP 计算卡(浮点数计算能力约为 25MFLOPS)。对于 1.3MB的网络参数，256KB 内存的计算机连网络参数都尚且装载不下，
更别提网络训练了。由此可见，全连接层较高的内存占用量严重限制了神经网络朝着更大规模、更深层数方向的发展。


10.1.1局部相关性
接下来我们探索如何避免全连接网络的参数量过大的缺陷。为了便于讨论，我们以图片类型数据为输入的场景为例。
对于 2D 的图片数据，在进入全连接层之前，需要将矩阵数据打平成 1D 向量，然后每个像素点与每个输出节点两两相连，
我们把连接关系非常形象地对应到图片的像素位置上，如图 10.2 所示。

可以看出，网络层的每个输出节点都与所有的输入节点相连接，用于提取所有输入节点的特征信息，这种稠密的连接方式是全连接层参数量大、
计算代价高的根本原因。全连接层也称为稠密连接层(Dense Layer)，输出与输入的关系为：
                        𝑜𝑗 = 𝜎 ( ∑ 𝑤𝑖𝑗𝑥𝑖 𝑖∈nodes(𝐼) + 𝑗)
其中nodes(𝐼)表示 I 层的节点集合。
那么，输出节点是否有必要和全部的输入节点相连接呢？有没有一种近似的简化模型呢？我们可以分析输入节点对输出节点的重要性分布，
仅考虑较重要的一部分输入节点，而抛弃重要性较低的部分节点，这样输出节点只需要与部分输入节点相连接，表达为：
                        𝑜𝑗 = 𝜎 ( ∑ 𝑤𝑖𝑗𝑥𝑖 𝑖∈top(𝐼 𝑗 𝑘) + 𝑗)

其中top(𝐼 𝑗 𝑘)表示 I 层中对于 J 层中的𝑗号节点重要性最高的前𝑘个节点集合。通过这种方式，
可以把全连接层的‖𝐼‖ ∙ ‖𝐽‖个权值连接减少到𝑘 ∙ ‖𝐽‖个，其中‖𝐼‖、‖𝐽‖分布表示 I、J 层的节点数量。

那么问题就转变为探索 I 层输入节点对于𝑗号输出节点的重要性分布。然而找出每个中间节点的重要性分布是件非常困难的事情，
我们可以针对于具体问题，利用先验知识把这个问题进一步简化。

在现实生活中，存在着大量以位置或距离作为重要性分布衡量标准的数据，比如和自己居住更近的人更有可能对自己影响更大(位置相关)，
股票的走势预测应该更加关注近段时间的数据趋势(时间相关)，图片每个像素点和周边像素点的关联度更大(位置相关)。
以 2D 图片数据为例，如果简单地认为与当前像素欧式距离(Euclidean Distance)小于和等于√𝑘2的像素点重要性较高，
欧式距离大于√𝑘2到像素点重要性较低，那么我们就很轻松地简化了每个像素点的重要性分布问题。
如图 10.3 所示，以实心网格所在的像素为参考点，它周边欧式距离小于或等于√𝑘2的像素点以矩形网格表示，网格内的像素点重要性较高，
网格外的像素点较低。这个高宽为𝑘的窗口称为感受野(Receptive Field)，它表征了每个像素对于中心像素的重要性分布情况，
网格内的像素才会被考虑，网格外的像素对于中心像素会被简单地忽略。

这种基于距离的重要性分布假设特性称为局部相关性，它只关注和自己距离较近的部分节点，而忽略距离较远的节点。在这种重要性分布假设下，
全连接层的连接模式变成了如图 10.4 所示，输出节点𝑗只与以𝑗为中心的局部区域(感受野)相连接，与其它像素无连接。

利用局部相关性的思想，我们把感受野窗口的高、宽记为𝑘(感受野的高、宽可以不相 等，为了便与表达，这里只讨论高宽相等的情况)，
当前位置的节点与大小为𝑘的窗口内的所有像素相连接，与窗口外的其它像素点无关，此时网络层的输入输出关系表达如下：
                        𝑜𝑗 = 𝜎 ( ∑ 𝑤𝑖𝑗𝑥𝑖 dist(𝑖 𝑗)≤√𝑘2 + 𝑗)
其中dist(𝑖 𝑗)表示节点𝑖、𝑗之间的欧式距离。


10.1.2权值共享
每个输出节点仅与感受野区域内𝑘 × 𝑘个输入节点相连接，输出层节点数为‖𝐽‖，则当前层的参数量为𝑘 × 𝑘 × ‖𝐽‖，
相对于全连接层的‖𝐼‖ × ‖𝐽‖，考虑到𝑘一般取值较小，如 1、 3、5 等，𝑘 × 𝑘 ≪ ‖𝐼‖，因此成功地将参数量减少了很多。

能否再将参数量进一步减少，比如只需要𝑘 × 𝑘个参数即可完成当前层的计算？答案是肯定的，通过权值共享的思想，对于每个输出节点𝑜𝑗，
均使用相同的权值矩阵𝑾，那么无论输出节点的数量‖𝐽‖是多少，网络层的参数量总是𝑘 × 𝑘。
如图 10.5 所示，在计算左上角位置的输出像素时，使用权值矩阵：
与对应感受野内部的像素相乘累加，作为左上角像素的输出值；在计算右下方感受野区域时，共享权值参数𝑾，即使用相同的权值参数𝑾相乘累加，
得到右下角像素的输出值，此时网络层的参数量只有3 × 3 = 9个，且与输入、输出节点数无关。

通过运用局部相关性和权值共享的思想，我们成功把网络的参数量从‖𝐼‖ × ‖𝐽‖减少到𝑘 × 𝑘(准确地说，是在单输入通道、单卷积核的条件下)。
这种共享权值的“局部连接层”网络其实就是卷积神经网络。接下来我们将从数学角度介绍卷积运算，进而正式学习卷积神经网络的原理与计算方法。


10.1.3卷积运算
在局部相关性的先验下，我们提出了简化的“局部连接层”，对于窗口𝑘 × 𝑘内的所有像素，采用权值相乘累加的方式提取特征信息，
每个输出节点提取对应感受野区域的特征信息。这种运算其实是信号处理领域的一种标准运算：离散卷积运算。
离散卷积运算在计算机视觉中有着广泛的应用，这里给出卷积神经网络层从数学角度的阐述。

在信号处理领域，1D 连续信号的卷积运算被定义两个函数的积分：函数𝑓(𝜏)、函数𝑔(𝜏)，其中𝑔(𝜏)经过了翻转𝑔(−𝜏)和平移后变成𝑔(𝑛 − 𝜏)。
卷积的“卷”是指翻转平移操作，“积”是指积分运算，1D 连续卷积定义为：
                    (𝑓⨂𝑔)(𝑛) = ∫−∞ ∞𝑓(𝜏)𝑔(𝑛 − 𝜏)d𝜏
离散卷积将积分运算换成累加运算：
                    (𝑓⨂𝑔)(𝑛) = ∑ 𝑓(𝜏)𝑔(𝑛 − 𝜏)
至于卷积为什么要这么定义，限于篇幅不做深入阐述。我们重点介绍 2D 离散卷积运算。在计算机视觉中，
卷积运算基于 2D 图片函数𝑓(𝑚 𝑛)和 2D 卷积核𝑔(𝑚 𝑛)，其中𝑓(𝑖 𝑗) 和𝑔(𝑖 𝑗)仅在各自窗口有效区域存在值，
其它区域视为 0，如图 10.6 所示。此时的 2D 离散卷积定义为：
                     𝑓⨂𝑔 (𝑚 𝑛) = ∑ ∑ 𝑓(𝑖 𝑗)𝑔(𝑚 − 𝑖， 𝑛 − 𝑗)

我们来详细介绍 2D 离散卷积运算。首先，将卷积核𝑔(𝑖 𝑗)函数翻转(沿着𝑥和𝑦方向各翻转一次)，变成𝑔(−𝑖 −𝑗)。当(𝑚 𝑛) = (− − )时，
𝑔(− − 𝑖 − − 𝑗)表示卷积核函数翻转后再向左、向上各平移一个单元，此时：
𝑓⨂𝑔 (− − ) = ∑ ∑ 𝑓(𝑖 𝑗)𝑔(− − 𝑖 − − 𝑗) ∞𝑗=−∞ ∞𝑖=−∞ = ∑ ∑ 𝑓(𝑖 𝑗)𝑔(− − 𝑖 − − 𝑗) 𝑗∈ −1 1 𝑖∈ −1 1
2D 函数只在𝑖 ∈ − 𝑗 ∈ − 存在有效值，其它位置为 0。按照计算公式，我们可以得到 𝑓⨂𝑔 ( − ) = ，如下图 10.7 所示：

同样的方法，(𝑚 𝑛) = (0， −1)时： 𝑓⨂𝑔 (0， −1) = ∑ ∑ 𝑓(𝑖 𝑗)𝑔( 0− 𝑖 , −1 − 𝑗)   𝑗∈ [−1 1] 𝑖∈ [−1 1]
即卷积核翻转后再向上平移一个单元后对应位置相乘累加， [𝑓⨂𝑔] (0, -1) = ，如图 10.8所示。

当(𝑚 𝑛) = (1, -1)时：
即卷积核翻转后再向右、向上各平移一个单元后对应位置相乘累加
当(𝑚 𝑛) = (−1, 0 )时：
即卷积核翻转后再向左平移一个单元后对应位置相乘累加
按照此种方式循环计算，可以计算出函数 𝑓⨂𝑔 (𝑚, -𝑚) 𝑚 ∈[−1 1], 𝑛∈[−1 1]的所有值，如下图 10.11 所示。

至此，我们成功完成图片函数与卷积核函数的卷积运算，得到一个新的特征图
回顾“权值相乘累加”的运算，我们把它记为 [𝑓 ∙ 𝑔 ](𝑚 , 𝑛)：

仔细比较它与标准的 2D 卷积运算不难发现，在“权值相乘累加”中的卷积核函数𝑔(𝑚 𝑛)，并没有经过翻转。
只不过对于神经网络来说，目标是学到一个函数𝑔(𝑚 𝑛)使得ℒ越小越好，至于𝑔(𝑚 𝑛)是不是恰好就是卷积运算中定义的“卷积核”函数并不十分重要，
因为我们并不会直接利用它。在深度学习中，函数𝑔(𝑚 𝑛)统一称为卷积核(Kernel)，有时也叫 Filter、Weight 等。
由于始终使用𝑔(𝑚 𝑛)函数完成卷积运算，卷积运算其实已经实现了权值共享的思想。

我们来小结 2D 离散卷积运算流程：每次通过移动卷积核，并与图片对应位置处的感受野像素相乘累加，得到此位置的输出值。
卷积核即是行、列为𝑘大小的权值矩阵𝑾，对应到特征图上大小为𝑘的窗口即为感受野，感受野与权值矩阵𝑾相乘累加，
得到此位置的输出值。通过权值共享，我们从左上方逐步向右、向下移动卷积核，提取每个位置上的像素特征，直至最右下方，完成卷积运算。
可以看出，两种理解方式殊途同归，从数学角度理解，卷积神经网络即是完成了 2D 函数的离散卷积运算；从局部相关与权值共享角度理解，
也能得到一样的效果。通过这两种角度，我们既能直观理解卷积神经网络的计算流程，又能严谨地从数学角度进行推导。
正是基于卷积运算，卷积神经网络才能如此命名。

在计算机视觉领域，2D 卷积运算能够提取数据的有用特征，通过特定的卷积核与输入图片进行卷积运算，获得不同特征的输出图片，
如下表 10.2 所示，列举了一些常见的卷积核及其效果样片。

[𝟎 𝟎 𝟎         [0 -1 0          [0.0625 0.125 0.0625         [-1 -1 -1
𝟎 𝟏 𝟎          -1 5 -1           0.125  0.25  0.125           -1  8 -1
𝟎 𝟎 𝟎]         0 -1 0]           0.0625 0.125 0.0625]         -1 -1 -1]
原图效果        锐化效果          模糊效果                   边缘提取效果
"""