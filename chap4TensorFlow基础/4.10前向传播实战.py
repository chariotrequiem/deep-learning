# å½“å‰ç‰ˆæœ¬ ï¼š python3.7.11
# å¼€å‘æ—¶é—´ ï¼š 2021/9/14 22:15
"""
åˆ°ç°åœ¨ä¸ºæ­¢ï¼Œæˆ‘ä»¬å·²ç»ä»‹ç»äº†å¦‚ä½•åˆ›å»ºå¼ é‡ã€å¯¹å¼ é‡è¿›è¡Œç´¢å¼•åˆ‡ç‰‡ã€ç»´åº¦å˜æ¢å’Œå¸¸è§çš„æ•°å­¦è¿ç®—ç­‰æ“ä½œã€‚
æœ€åæˆ‘ä»¬å°†åˆ©ç”¨å·²ç»å­¦åˆ°çš„çŸ¥è¯†å»å®Œæˆä¸‰å±‚ç¥ç»ç½‘ç»œçš„å®ç°ï¼š
                    out = ğ‘…ğ‘’ğ¿ğ‘ˆ{ğ‘…ğ‘’ğ¿ğ‘ˆ{ğ‘…ğ‘’ğ¿ğ‘ˆ[ğ‘¿@ğ‘¾1 + ğ’ƒ1]@ğ‘¾2 + ğ’ƒ2}@ğ‘¾3 + ğ’ƒ3}
æˆ‘ä»¬é‡‡ç”¨çš„æ•°æ®é›†æ˜¯MNISTæ‰‹å†™æ•°å­—å›¾ç‰‡é›†ï¼Œè¾“å…¥èŠ‚ç‚¹æ•°ä¸º784ï¼Œç¬¬ä¸€å±‚çš„è¾“å‡ºèŠ‚ç‚¹æ•°æ˜¯256ï¼Œç¬¬äºŒå±‚çš„è¾“å‡ºèŠ‚ç‚¹æ˜¯128ï¼Œ
ç¬¬ä¸‰å±‚çš„è¾“å‡ºèŠ‚ç‚¹æ˜¯10ï¼Œä¹Ÿå°±æ˜¯å½“å‰æ ·æœ¬å±äº10ç±»åˆ«çš„æ¦‚ç‡ã€‚
"""
import tensorflow as tf
# é¦–å…ˆåˆ›å»ºæ¯ä¸ªéçº¿æ€§å±‚çš„ğ‘¾å’Œbå¼ é‡å‚æ•°ï¼Œä»£ç å¦‚ä¸‹ï¼š
# æ¯å±‚çš„å¼ é‡éƒ½éœ€è¦è¢«ä¼˜åŒ–ï¼Œæ•…ä½¿ç”¨Variableç±»å‹ï¼Œå¹¶ä½¿ç”¨æˆªæ–­çš„æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–æƒå€¼å¼ é‡
# åç½®å‘é‡åˆå§‹åŒ–ä¸º0å³å¯
# ç¬¬ä¸€å±‚çš„å‚æ•°
# tf.random.truncated_normaläº§ç”Ÿæˆªæ–­æ­£æ€åˆ†å¸ƒéšæœºæ•°ï¼Œå–å€¼èŒƒå›´ä¸º[ mean - 2 * stddev, mean + 2 * stddev ]
w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1))
b1 = tf.Variable(tf.zeros([256]))

# ç¬¬äºŒå±‚çš„å‚æ•°
w2 = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1))
b2 = tf.Variable(tf.zeros([128]))

# ç¬¬ä¸‰å±‚çš„å‚æ•°
w3 = tf.Variable(tf.random.truncated_normal([128, 10], stddev=0.1))
b3 = tf.Variable(tf.zeros([10]))

"""
åœ¨å‰å‘è®¡ç®—æ—¶ï¼Œé¦–å…ˆå°†shapeä¸º[b, 28, 28]çš„è¾“å…¥å¼ é‡çš„è§†å›¾è°ƒæ•´ä¸º[b, 784],
å³å°†æ¯ä¸ªå›¾ç‰‡çš„çŸ©é˜µæ•°æ®è°ƒæ•´ä¸ºå‘é‡ç‰¹å¾ï¼Œè¿™æ ·æ‰é€‚åˆäºç½‘æ ¼çš„è¾“å…¥æ ¼å¼;
"""
# æ”¹å˜è§†å›¾ï¼Œ[b, 28, 28] => [b, 28*28]
x = tf.reshape(x, [-1, 28*28])

# æ¥ä¸‹æ¥å®Œæˆç¬¬ä¸€ä¸ªå±‚çš„è®¡ç®—ï¼Œè¿™é‡Œæ˜¾ç¤ºåœ°è¿›è¡Œè‡ªåŠ¨æ‰©å±•æ“ä½œ;
# ç¬¬ä¸€å±‚è®¡ç®—ï¼Œ[b, 784]@[784, 256] + [256] => [b, 256] + [256] => [b, 256] + [b, 256]
h1 = x@w1 + tf.broadcast_to(b1, [x.shape[0], 256])
h1 = tf.nn.relu(h1)  # é€šè¿‡æ¿€æ´»å‡½æ•°

# ç”¨åŒæ ·çš„æ–¹å¼å®Œæˆç¬¬äºŒä¸ªå’Œç¬¬ä¸‰ä¸ªéçº¿æ€§å‡½æ•°å±‚çš„å‰å‘è®¡ç®—ï¼Œè¾“å‡ºå±‚å¯ä»¥ä¸ä½¿ç”¨ReLUæ¿€æ´»å‡½æ•°ï¼š
# ç¬¬äºŒå±‚è®¡ç®—ï¼Œ[b, 256] => [b, 128]
h2 = h1@w2 + b2
h2 = tf.nn.relu(h2)
# è¾“å‡ºå±‚è®¡ç®—ï¼Œ[b, 128] => [b, 10]
out = h2@w3 + b3

# å°†çœŸå®çš„æ ‡æ³¨å¼ é‡yè½¬å˜ä¸ºOne-hotç¼–ç ï¼Œå¹¶è®¡ç®—ä¸outçš„å‡æ–¹å·®ï¼Œä»£ç å¦‚ä¸‹ï¼š
# è®¡ç®—ç½‘ç»œè¾“å‡ºä¸æ ‡ç­¾ä¹‹é—´çš„å‡æ–¹å·®ï¼Œmse = mean(sum(y-out)^2)
# [b, 10]
loss = tf.square(y_onehot - out)
# è¯¯å·®æ ‡é‡ï¼Œmean: scalar
loss = tf.reduce_mean(loss)

"""
ä¸Šè¿°çš„å‰å‘è®¡ç®—è¿‡ç¨‹éƒ½éœ€è¦åŒ…è£¹åœ¨with.tf.GradientTape() as tapeä¸Šä¸‹æ–‡ä¸­ï¼Œä½¿çš„å‰å‘è®¡ç®—æ—¶èƒ½å¤Ÿä¿å­˜è®¡ç®—å›¾ä¿¡æ¯ï¼Œæ–¹ä¾¿è‡ªåŠ¨æ±‚å¯¼æ“ä½œã€‚
é€šè¿‡tape.gradient()å‡½æ•°æ±‚å¾—ç½‘ç»œå‚æ•°åˆ°æ¢¯åº¦ä¿¡æ¯ï¼Œç»“æœä¿å­˜åœ¨gradsåˆ—è¡¨å˜é‡ä¸­ï¼Œå®ç°å¦‚ä¸‹ï¼š
"""
# è‡ªåŠ¨æ¢¯åº¦ï¼Œéœ€è¦æ±‚æ¢¯åº¦çš„å¼ é‡æœ‰[w1, b1, w2, b2, w3, b3]
grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])
# å¹¶æŒ‰ç…§     æ¥æ›´æ–°ç½‘ç»œå‚æ•°
# æ¢¯åº¦æ›´æ–°ï¼Œassign_sub å°†å½“å‰å€¼å‡å»å‚æ•°å€¼ï¼ŒåŸåœ°æ›´æ–°
w1.assign_sub(lr * grads[0])
b1.assign_sub(lr * grads[1])
w2.assign_sub(lr * grads[2])
b2.assign_sub(lr * grads[3])
w3.assign_sub(lr * grads[4])
b3.assign_sub(lr * grads[5])

# å…¶ä¸­ assign_sub()å°†è‡ªèº«å‡å»ç»™å®šçš„å‚æ•°å€¼ï¼Œå®ç°å‚æ•°çš„åŸåœ°(In-place)æ›´æ–°æ“ä½œã€‚ç½‘ç»œè®­ç»ƒè¯¯å·®å€¼çš„å˜åŒ–æ›²çº¿å¦‚å›¾ 4.11 æ‰€ç¤ºã€‚